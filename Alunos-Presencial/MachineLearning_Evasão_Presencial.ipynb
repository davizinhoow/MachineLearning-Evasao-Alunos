{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22328f00",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING PARA CALCULAR A EVASÃO DOS ALUNOS DO PERÍODO PRESENCIAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0af899a",
   "metadata": {},
   "source": [
    "### IMPORTAÇÕES NESCESSÁRIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc7aa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "\n",
    "\n",
    "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ed9c64",
   "metadata": {},
   "source": [
    "### IMPORTANDO A TABELA BASE DO EXEL , COM OS DADOS QUE FORAM BUSCADOS, E UMA CONSULTA NO BANCO DE DADOS\n",
    "\n",
    "\n",
    "### TRANSFORMA AS COLUNAS DE SIM E NÃO, EM BINÁRIAS, E AS DEMAIS COLUNAS EM FLOAT, TRANSFORMANDO OS VALORES NULOS PARA ZERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa62a117",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "df                  = pd.read_excel('Base_dados.xlsx')\n",
    "df['EVADIDO']       = df['EVADIDO'].apply(lambda valor: 1 if valor == 'S' else 0 )\n",
    "df['DP']            = df['DP'].apply(lambda valor: 1 if valor == 'S' else 0 )\n",
    "df['REP_FREQ']      = df['REP_FREQ'].apply(lambda valor: 1 if valor == 'S' else 0 )\n",
    "df['INADIMPLENTE']  = df['INADIMPLENTE'].apply(lambda valor: 1 if valor == 'S' else 0 )\n",
    "\n",
    "\n",
    "df['QTD_MESES_INADI'] = pd.to_numeric(df['QTD_MESES_INADI'], errors='coerce').fillna(0).astype(int)\n",
    "df['QTD_DP'] = pd.to_numeric(df['QTD_DP'], errors='coerce').fillna(0).astype(int)\n",
    "df['MEDIA_DP_POR_INADI'] = pd.to_numeric(df['MEDIA_DP_POR_INADI'], errors='coerce').fillna(0).astype(float)\n",
    "df['MEDIA_COBRANCAS'] = pd.to_numeric(df['MEDIA_COBRANCAS'], errors='coerce').fillna(0).astype(float)\n",
    "df['PERFIL_RISCO'] = pd.to_numeric(df['PERFIL_RISCO'], errors='coerce').fillna(0).astype(float)\n",
    "df['QTD_PERIODOS'] = pd.to_numeric(df['QTD_PERIODOS'], errors='coerce').fillna(0).astype(float)\n",
    "df['CURSO'] = pd.to_numeric(df['CURSO'], errors='coerce').fillna(0).astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db69858a",
   "metadata": {},
   "source": [
    "### DECLARA AS COLUNAS DE BASE(X), E A DE SAÍDA (Y), OS EVADIDOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2d5b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['CURSO', 'INADIMPLENTE', 'DP', 'QTD_DP', 'QTD_MESES_INADI', 'MEDIA_DP_POR_INADI','MEDIA_COBRANCAS','PERFIL_RISCO','QTD_PERIODOS']]\n",
    "y = df['EVADIDO']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792a96d8",
   "metadata": {},
   "source": [
    "### LIGHTGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ff6bf1",
   "metadata": {},
   "source": [
    "### Criando modelo com uma pipeline de execução\n",
    "\n",
    "Usei o ImbPipeline para deixar o trabalho mais organizado ao invés de ter diversas partes realizando todo processo. Desta forma eu consigo utilizar o smote (primeira parte), para fazer a sintetização de dados e deixa-los balanceados. O Scaler para organizar as informações em pesos e obter um melhor resultado no processo de treinamento e por fim criar o modelo e realizar todo o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2844217b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Pipeline com SMOTE + scaler + LGBM com pesos\n",
    "lgb_pipeline = ImbPipeline([\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LGBMClassifier(\n",
    "        objective='binary',\n",
    "        metric='auc',\n",
    "        n_estimators=1000,\n",
    "        class_weight='balanced',  \n",
    "        random_state=42\n",
    "    )),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728da403",
   "metadata": {},
   "source": [
    "### Melhorando meu modelo\n",
    "\n",
    "Utilizei o Grid Search CV para melhorar meu modelo com o apoio do Dandomized Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202cfec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scorer = make_scorer(f1_score, pos_label=1)\n",
    "recall_scorer = make_scorer(recall_score, pos_label=1)\n",
    "precision_scorer = make_scorer(precision_score, pos_label=1)\n",
    "\n",
    "\n",
    "scoring = {\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "}\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'clf__learning_rate': [0.01, 0.1],\n",
    "    'clf__num_leaves': [31, 64],\n",
    "    'clf__max_depth': [5, 10, -1],\n",
    "}\n",
    "\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=lgb_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scoring,\n",
    "    refit='recall',  # foco em recall da evasão\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "y_probs = grid.predict_proba(X_test)[:, 1]\n",
    "y_pred_thresh = (y_probs >= 0.4).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_thresh))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_thresh))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_thresh))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faab4286",
   "metadata": {},
   "source": [
    "### Analisando os resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6ab58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_proba_lgb = grid.best_estimator_.predict_proba(X)[:, 1]\n",
    "\n",
    "\n",
    "pr_table = []\n",
    "\n",
    "print(\"\\n### Resultados LightGBM com melhores params ###\\n\")\n",
    "for thresh in [0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49]:\n",
    "    y_pred = (y_proba_lgb > thresh).astype(int)\n",
    "    print(f\"--- Threshold: {thresh} ---\")\n",
    "\n",
    "    \n",
    "    report = classification_report(y, y_pred)\n",
    "    print(report)\n",
    "\n",
    "    # Extrai precision e recall da classe 1 (3ª linha)\n",
    "    linha_classe1 = report.split('\\n')[3].split()\n",
    "    precision = float(linha_classe1[1])\n",
    "    recall = float(linha_classe1[2])\n",
    "\n",
    "    # Adiciona dicionário à lista\n",
    "    pr_table.append({\n",
    "        'threshold': thresh,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    })\n",
    "\n",
    "# Converte para DataFrame\n",
    "pr_table = pd.DataFrame(pr_table)\n",
    "\n",
    "# Filtra e ordena os resultados relevantes\n",
    "relevantes = pr_table[(pr_table['recall'] > 0.6) & (pr_table['precision'] > 0.5)]\n",
    "relevantes = relevantes.sort_values(by='recall', ascending=False)\n",
    "\n",
    "print(relevantes.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a35f171",
   "metadata": {},
   "source": [
    "## MATRIZ DE CONFUSÃO PARA VERMOS OS RESULTADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a3e3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_proba_lgb > 0.34).astype(int)\n",
    "matriz = confusion_matrix(y, y_pred) #y (valores reais) e y_pred (valores previstos)\n",
    "sns.heatmap(matriz, annot=True, fmt='d', cmap='Greens',\n",
    "            xticklabels=['Não Evadiu (prev)', 'Evadiu (prev)'],\n",
    "            yticklabels=['Não Evadiu (real)', 'Evadiu (real)'])\n",
    "plt.xlabel('Previsão')\n",
    "plt.ylabel('Realidade')\n",
    "plt.title('Matriz de Confusão 0.34')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa261cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = y_proba_lgb  \n",
    " \n",
    "precisions, recalls, thresholds = precision_recall_curve(y, y_scores)\n",
    " \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds, precisions[:-1], 'b--', label='Precision')\n",
    "plt.plot(thresholds, recalls[:-1], 'g-', label='Recall')\n",
    "plt.xlabel('Threshold de corte')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Precision vs Recall vs Threshold')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36b6175",
   "metadata": {},
   "source": [
    "## IMPORTANDO NOSSO MODELO PARA APLICAR DIA A DIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbad96f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina seu threshold\n",
    "threshold = 0.34\n",
    "\n",
    "# Empacote o modelo e o threshold em um dicionário\n",
    "modelo_completo = {\n",
    "    'modelo': grid,\n",
    "    'threshold': threshold\n",
    "}\n",
    "\n",
    "# Salve \n",
    "with open('modelo_lgb_com_threshold_034_real.pkl', 'wb') as f:\n",
    "    pickle.dump(modelo_completo, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
